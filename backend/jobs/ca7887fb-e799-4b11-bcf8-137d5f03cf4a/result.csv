timestamp,raw,final_label,severity,owner_team,tags,cluster_id,t5_template,cluster_template,auto_label
2025-09-03T07:52:15.220,[2025-09-03T07:52:15.220] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,infra",1,Gres_FILE Gpu=l4=l4 [2025-09-03T07:52:15.220] Gres Name=gpu Type=l4 Count=1 Gres Gres Gres2025-09-03T07,[2025-09-03T07:52:15.220] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update
2025-09-03T07:52:15.221,[2025-09-03T07:52:15.221] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,infra",1,Gres_FILE Gres=l4 [2025-09-03T07:52:15.221] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE Gres Name=gpu Type=l4 Count,<*> Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update
2025-09-03T07:52:15.222,[2025-09-03T07:52:15.222] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,infra",1,Gres=gpu Gres [2025-09-03T07:52:15.222] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE] Gres Name=gpu Type=l4 Count=1,<*> Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update
2025-09-03T07:52:15.223,[2025-09-03T07:52:15.223] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,infra",1,Gres_FILE gpu=l4 [2025-09-03T07:52:15.223] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE] Gres Name=gpu Type=l4,<*> Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update
2025-09-03T07:52:15.224,[2025-09-03T07:52:15.224] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,infra",1,Gres=gpu Gres [2025-09-03T07:52:15.224] Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE] Gres Name=gpu Type=l4 Count=1,<*> Gres Name=gpu Type=l4 Count=1 Flags=HAS_FILE,gpu_inventory_update
2025-09-03T07:54:51.273,[2025-09-03T07:54:51.273] POWER: Power save mode: 334 nodes,cluster_power_save_mode,info,infra,"power,save,cluster,infra",2,[2025-09-03T07:54:51.273] POWER: Power save mode: 334 nodes [2025-09-03T07:54:51.273] POWER: Power save mode: 334 nodes [2025-09-03T07:54:,[2025-09-03T07:54:51.273] POWER: Power save mode: 334 nodes,cluster_power_save_mode
2025-09-03T08:05:11.347,[2025-09-03T08:05:11.347] POWER: Power save mode: 334 nodes,cluster_power_save_mode,info,infra,"power,save,cluster,infra",2,[2025-09-03T08:05:11.347] POWER: Power save mode: 334 nodes [2025-09-03T08:05:11.347] POWER: Power save mode: 334 nodes [2025-09-03T08:05:,<*> POWER: Power save mode: 334 nodes,cluster_power_save_mode
2025-09-03T08:15:31.423,[2025-09-03T08:15:31.423] POWER: Power save mode: 334 nodes,cluster_power_save_mode,info,infra,"power,save,cluster,infra",2,[2025-09-03T08:15:31.423] POWER: Power save mode: 334 nodes [2025-09-03T08:15:31.423] POWER: Power save mode: 334 nodes [2025-09-03T08:15:,<*> POWER: Power save mode: 334 nodes,cluster_power_save_mode
2025-09-03T08:25:51.498,[2025-09-03T08:25:51.498] POWER: Power save mode: 334 nodes,cluster_power_save_mode,info,infra,"power,save,cluster,infra",2,[2025-09-03T08:25:51.498] POWER: Power save mode: 334 nodes: [2025-09-03T08:25:51.498] POWER:. [2025-09-03T08:25:51.4,<*> POWER: Power save mode: 334 nodes,cluster_power_save_mode
2025-09-03T07:53:16.000,[2025-09-03T07:53:16.000] SchedulerParameters=preempt_youngest_first,scheduler_parameters,info,scheduler,"scheduler,config,preempt",3,[2025-09-03T07:53:16.000] [2025-09-03T07:53:16.000] [2025-09-03T07:53:16.000] [2025-09-03T07:53:16.000]_,[2025-09-03T07:53:16.000] SchedulerParameters=preempt_youngest_first,scheduler_parameters
2025-09-03T07:53:16.001,[2025-09-03T07:53:16.001] SchedulerParameters=bf_resolution=60,scheduler_parameters,info,scheduler,"scheduler,config,bf_resolution",4,[2025-09-03T07:53:16.001] SchedulerParameters=bf_resolution=60 [2025-09-03T07:53:16.001] [2025-09-03T07:53:16.001],[2025-09-03T07:53:16.001] SchedulerParameters=bf_resolution=60,scheduler_parameters
2025-09-03T07:53:16.002,[2025-09-03T07:53:16.002] SchedulerParameters=bf_window=4320,scheduler_parameters,info,scheduler,"scheduler,config,bf_window",5,[2025-09-03T07:53:16.002] SchedulerParameters=bf_window=4320 [2025-09-03T07:53:16.002] SchedulerParameters=bf_window=432020,[2025-09-03T07:53:16.002] SchedulerParameters=bf_window=4320,scheduler_parameters
2025-09-03T07:52:15.244,[2025-09-03T07:52:15.244] select/cons_tres: preparing for 19 partitions,scheduler_config_event,info,scheduler,"scheduler,config,select,prepare",6,/con_tres: preparing for 19 partitions. [2025-09-03T07:52:15.244] select/cons_tres: preparing for 19 partitions. [2025-09-03T07:52:15.244] select/cons_tre,[2025-09-03T07:52:15.244] select/cons_tres: preparing for 19 partitions,scheduler_config_event
2025-09-03T07:52:15.244,[2025-09-03T07:52:15.244] select/cons_tres: reconfigure,scheduler_config_event,info,scheduler,"scheduler,config,select,reconfigure",7,[2025-09-03T07:52:15.244] select/cons_tres: reconfigure [2025-09-03T07:52:15.244] select/cons_tres: reconfigure [2025-09-03T07:52:15.2,[2025-09-03T07:52:15.244] select/cons_tres: reconfigure,scheduler_config_event
2025-09-03T07:52:15.244,[2025-09-03T07:52:15.244] Recovered state of 0 reservations,cluster_state_recovered_no_reservations,info,scheduler,"cluster,state,reservations,recovered",8,[2025-09-03T07:52:15.244] Recovered state of 0 reservations. [2025-09-03T07:52:15.244] [2025-09-03T07:52:15.244] Recovered state of 0 reservations. [,[2025-09-03T07:52:15.244] Recovered state of 0 reservations,cluster_state_recovered_no_reservations
2025-09-03T07:52:15.244,[2025-09-03T07:52:15.244] State of 0 triggers recovered,cluster_state_recovered_no_triggers,info,scheduler,"cluster,state,triggers,recovered",9,[2025-09-03T07:52:15.244].] [2025-09-03T07:52:15.244]] [2025-09-03T07:52:15.244] [2025-09-03T07:52:,[2025-09-03T07:52:15.244] State of 0 triggers recovered,cluster_state_recovered_no_triggers
2025-09-03T07:52:15.226,[2025-09-03T07:52:15.226] Running as primary controller,controller_primary,info,infra,"controller,primary,infra",10,[2025-09-03T07:52:15.226] Running as primary controller. [2025-09-03T07:52:15.226] Running as primary controller.,[2025-09-03T07:52:15.226] Running as primary controller,controller_primary
2025-09-03T07:52:15.245,[2025-09-03T07:52:15.245] read_slurm_conf: backup_controller not specified,controller_backup_not_configured,warning,infra,"controller,backup,not_configured",11,[2025-09-03T07:52:15.245] read_slurm_conf: backup_controller not specified [2025-09-03T07:52:15.245] read_slurm_conf: backup_controller not specified [2025-0,[2025-09-03T07:52:15.245] read_slurm_conf: backup_controller not specified,controller_backup_not_configured
2025-09-03T07:52:15.236,[2025-09-03T07:52:15.236] Gres Name=gpu Type=l4 Count=4 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,count4",1,Gres=gpugpu=4 [2025-09-03T07:52:15.236] Gres Name=gpu Type=l4 Count=4 [2025-09-03T07:52:15.236] Gres Name=gpu,<*> Gres Name=gpu Type=l4 <*> Flags=HAS_FILE,gpu_inventory_update
2025-09-03T07:52:15.235,[2025-09-03T07:52:15.235] Gres Name=gpu Type=l4 Count=8 Flags=HAS_FILE,gpu_inventory_update,info,infra,"gpu,l4,inventory,count8",1,Gres=gpugpu [2025-09-03T07:52:15.235] Gres Name=gpu Type=l4 Count=8 Flags=HAS_FILE] Gres Name=gpu Type=l4 Count=8,<*> Gres Name=gpu Type=l4 <*> Flags=HAS_FILE,gpu_inventory_update
2025-09-03T09:10:00.001,[2025-09-03T09:10:00.001] AUTH: user alice failed password authentication from 10.1.2.3 (error=INVALID_CREDENTIALS),auth_failure,high,security,"auth,failed,password,invalid_credentials",12,user alice failed password authentication from 10.1.2.3 (error=INVALID_CREDENTIALS) (user alice failed password authentication from 10.1.2.3) user alice failed password authentication from 10.1.2.3 (error=INVALID_CREDENTIALS,[2025-09-03T09:10:00.001] AUTH: user alice failed password authentication from 10.1.2.3 (error=INVALID_CREDENTIALS),auth_failure
2025-09-03T09:10:05.123,[2025-09-03T09:10:05.123] DISK: /var is 92% full on node cpu-16c-std-01 (warning: low free space),disk_usage_high,warning,storage,"disk,usage,full,low_space",13,/var is 92% full on node cpu-16c-std-01 (warning: low free space) [2025-09-03T09:10:05.123] [ [2025-09-03T09:10:05.123,[2025-09-03T09:10:05.123] DISK: /var is 92% full on node cpu-16c-std-01 (warning: low free space),disk_usage_high
2025-09-03T09:10:07.456,[2025-09-03T09:10:07.456] DISK: scrubber error while cleaning temp files on node cpu-8c-std-02,disk_scrubber_error,high,storage,"disk,scrubber,error,temp_files",14,-scrubber-error-while-cleaning-temp files on node cpu-8c-std-02-02 error while cleaning temp files on node-02 [2025-09-03T09:10:07.456] [202,[2025-09-03T09:10:07.456] DISK: scrubber error while cleaning temp files on node cpu-8c-std-02,disk_scrubber_error
2025-09-03T09:10:10.789,[2025-09-03T09:10:10.789] JOB 987654 submitted by user bob to partition gpu-long (priority=high),job_submit_gpu_long,info,scheduler,"job,submit,gpu-long,priority_high",15,[2025-09-03T09:10:10.789] [2025-09-03T09:10:10.789] [2025-09-03T09:10:10.789] [2025-09-03T09:10:10.789] [202,[2025-09-03T09:10:10.789] JOB 987654 submitted by user bob to partition gpu-long (priority=high),job_submit_gpu_long
2025-09-03T09:10:12.000,[2025-09-03T09:10:12.000] NETWORK: latency to storage cluster increased to 120ms (no SLA breach),network_latency_storage_cluster,warning,network,"network,latency,storage_cluster",16,[2025-09-03T09:10:12.000] [2025-09-03T09:10:12.000] [2025-09-03T09:10:12.000] [2025-09-03T09:10:12.000] [2025-09-03,[2025-09-03T09:10:12.000] NETWORK: latency to storage cluster increased to 120ms (no SLA breach),network_latency_storage_cluster
